{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step 52.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZxZtLcO1rV2",
        "outputId": "608aae4a-9251-4418-bdbe-2e203e0d209d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/Shareddrives/Data/밑바닥부터 시작하는 딥러닝\n"
          ]
        }
      ],
      "source": [
        "from graphviz import Source\n",
        "from IPython.display import Image\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shareddrives/Data/밑바닥부터 시작하는 딥러닝"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 52 - MNIST ON GPU"
      ],
      "metadata": {
        "id": "yHB5_OG2CPim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import dezero\n",
        "import dezero.functions as F\n",
        "import dezero.datasets as dsets\n",
        "from dezero import optimizers\n",
        "from dezero import DataLoader\n",
        "from dezero.models import MLP\n",
        "\n",
        "max_epoch = 5\n",
        "batch_size = 100\n",
        "\n",
        "train_set = dsets.MNIST(train=True)\n",
        "train_loader = DataLoader(train_set, batch_size)\n",
        "model = MLP((1000, 10))\n",
        "optimizer = optimizers.SGD().setup(model)\n",
        "\n",
        "# GPU\n",
        "train_loader.to_gpu()\n",
        "model.to_gpu()\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    start = time.time()\n",
        "    sum_loss = 0\n",
        "\n",
        "    for x, t in train_loader:\n",
        "        y = model(x)\n",
        "        loss = F.softmax_cross_entropy(y, t)\n",
        "        model.cleargrads()\n",
        "        loss.backward()\n",
        "        optimizer.update()\n",
        "        sum_loss += float(loss.data) * len(t)\n",
        "\n",
        "    elasped_time = time.time() - start\n",
        "    print(f'epoch: {epoch+1}, loss: {sum_loss / len(train_set):.4f}, time:{elasped_time:4f}[sec]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAi4i9kpCVQx",
        "outputId": "c04ae5d0-b432-44ef-85dc-602df920baa6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 1.9290, time:3.659137[sec]\n",
            "epoch: 2, loss: 1.2907, time:3.757802[sec]\n",
            "epoch: 3, loss: 0.9243, time:3.619218[sec]\n",
            "epoch: 4, loss: 0.7373, time:3.533551[sec]\n",
            "epoch: 5, loss: 0.6325, time:3.572593[sec]\n"
          ]
        }
      ]
    }
  ]
}